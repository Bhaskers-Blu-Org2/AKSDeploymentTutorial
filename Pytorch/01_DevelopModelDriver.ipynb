{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop Model Driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will develop the API that will call our model. This module initializes the model, transforms the input so that it is in the appropriate format and defines the scoring method that will produce the predictions. The API will expect the input to be in JSON format. Once  a request is received, the API will convert the json encoded request body into the image format. There are two main functions in the API. The first function loads the model and returns a scoring function. The second function process the images and uses the first function to score them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from testing_utilities import img_url_to_json\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the writefile magic to write the contents of the below cell to driver.py which includes the driver methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "lines_to_end_of_cell_marker": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting driver.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile driver.py \n",
    "import base64\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import timeit as t\n",
    "from io import BytesIO\n",
    "\n",
    "import PIL\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from torchvision import models, transforms\n",
    "\n",
    "\n",
    "\n",
    "_LABEL_FILE = os.getenv(\"LABEL_FILE\", \"synset.txt\")\n",
    "_NUMBER_RESULTS = 3\n",
    "\n",
    "\n",
    "def _create_label_lookup(label_path):\n",
    "    with open(label_path, \"r\") as f:\n",
    "        label_list = [l.rstrip() for l in f]\n",
    "\n",
    "    def _label_lookup(*label_locks):\n",
    "        return [label_list[l] for l in label_locks]\n",
    "\n",
    "    return _label_lookup\n",
    "\n",
    "\n",
    "def _load_model():\n",
    "    # Load the model\n",
    "    model = models.resnet152(pretrained=True)\n",
    "    model = model.cuda()\n",
    "    softmax = nn.Softmax(dim=1).cuda()\n",
    "    model = model.eval()\n",
    "\n",
    "    preprocess_input = transforms.Compose(\n",
    "        [\n",
    "            torchvision.transforms.Resize((224, 224), interpolation=PIL.Image.BICUBIC),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    def predict_for(images):\n",
    "        with torch.no_grad():\n",
    "            batch = preprocess_input(image).unsqueeze(0)\n",
    "            batch_gpu = batch.type(torch.float).cuda()\n",
    "            outputs = model(batch_gpu)\n",
    "            pred_proba = softmax(outputs)\n",
    "        return pred_proba.cpu().numpy().squeeze()\n",
    "\n",
    "    return predict_for\n",
    "\n",
    "\n",
    "def _base64img_to_pil_image(base64_img_string):\n",
    "    if base64_img_string.startswith(\"b'\"):\n",
    "        base64_img_string = base64_img_string[2:-1]\n",
    "    base64Img = base64_img_string.encode(\"utf-8\")\n",
    "\n",
    "    # Preprocess the input data\n",
    "    decoded_img = base64.b64decode(base64Img)\n",
    "    img_buffer = BytesIO(decoded_img)\n",
    "\n",
    "    # Load image with PIL (RGB)\n",
    "    pil_img = Image.open(img_buffer).convert(\"RGB\")\n",
    "    return pil_img\n",
    "\n",
    "def _image_ref_to_pil_image(image_ref):\n",
    "    # Load image with PIL (RGB)\n",
    "    return Image.open(image_ref).convert(\"RGB\")\n",
    "\n",
    "\n",
    "def create_scoring_func(label_path=_LABEL_FILE):\n",
    "    logger = logging.getLogger(\"model_driver\")\n",
    "\n",
    "    start = t.default_timer()\n",
    "    labels_for = _create_label_lookup(label_path)\n",
    "    predict_for = _load_model()\n",
    "    end = t.default_timer()\n",
    "\n",
    "    loadTimeMsg = \"Model loading time: {0} ms\".format(round((end - start) * 1000, 2))\n",
    "    logger.info(loadTimeMsg)\n",
    "\n",
    "    def call_model(images, number_results=_NUMBER_RESULTS):\n",
    "        pred_proba = predict_for(images)\n",
    "        selected_results = np.flip(np.argsort(pred_proba), 0)[:number_results]\n",
    "        labels = labels_for(*selected_results)\n",
    "        return list(zip(labels, pred_proba[selected_results].astype(np.float64)))\n",
    "\n",
    "    return call_model\n",
    "\n",
    "\n",
    "def get_model_api():\n",
    "    logger = logging.getLogger(\"model_driver\")\n",
    "    scoring_func = create_scoring_func()\n",
    "\n",
    "    def process_and_score(images_dict, number_results=_NUMBER_RESULTS):\n",
    "        start = t.default_timer()\n",
    "\n",
    "        keys = list(images_dict.keys())\n",
    "        images = [_image_ref_to_pil_image(images_dict[key]) for key in keys]\n",
    "        results = scoring_func(images, number_results=number_results)\n",
    "        results = {}\n",
    "        for key, image_ref in images_dict.items():\n",
    "            rgb_image = _image_ref_to_pil_image(image_ref)\n",
    "            results[key] = scoring_func(rgb_image, number_results=number_results)\n",
    "\n",
    "        end = t.default_timer()\n",
    "\n",
    "        logger.info(\"Predictions: {0}\".format(results))\n",
    "        logger.info(\"Predictions took {0} ms\".format(round((end - start) * 1000, 2)))\n",
    "        return (results, \"Computed in {0} ms\".format(round((end - start) * 1000, 2)))\n",
    "\n",
    "    return process_and_score\n",
    "\n",
    "\n",
    "def version():\n",
    "    return torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the file driver.py which will bring everything into the context of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run driver.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the same Lynx image we used ealier to check that our driver works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGEURL = \"https://upload.wikimedia.org/wikipedia/commons/thumb/6/68/Lynx_lynx_poing.jpg/220px-Lynx_lynx_poing.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:model_driver:Model loading time: 1712.11 ms\n"
     ]
    }
   ],
   "source": [
    "predict_for = get_model_api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-10-08 18:42:00--  https://upload.wikimedia.org/wikipedia/commons/thumb/6/68/Lynx_lynx_poing.jpg/220px-Lynx_lynx_poing.jpg\n",
      "Resolving upload.wikimedia.org... 208.80.153.240, 2620:0:860:ed1a::2:b\n",
      "Connecting to upload.wikimedia.org|208.80.153.240|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 27183 (27K) [image/jpeg]\n",
      "Saving to: ‘220px-Lynx_lynx_poing.jpg.2’\n",
      "\n",
      "220px-Lynx_lynx_poi 100%[===================>]  26.55K  --.-KB/s    in 0.04s   \n",
      "\n",
      "2018-10-08 18:42:00 (689 KB/s) - ‘220px-Lynx_lynx_poing.jpg.2’ saved [27183/27183]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget {IMAGEURL}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('220px-Lynx_lynx_poing.jpg', 'rb') as f:\n",
    "    img_data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.7158181e-08 1.1402593e-08 4.8121733e-09 ... 3.7173081e-07\n",
      "  3.7724925e-07 9.7586671e-08]\n",
      " [1.7158181e-08 1.1402593e-08 4.8121733e-09 ... 3.7173081e-07\n",
      "  3.7724925e-07 9.7586671e-08]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-71b226ef1550>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# json_load_img = json.loads(jsonimg)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# body = json_load_img[\"input\"]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'key'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'220px-Lynx_lynx_poing.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'key2'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'220px-Lynx_lynx_poing.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/repos/AKSDeploymentTutorial/Pytorch/driver.py\u001b[0m in \u001b[0;36mprocess_and_score\u001b[0;34m(images_dict, number_results)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_image_ref_to_pil_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscoring_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumber_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;31m#         for key, image_ref in images_dict.items():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/AKSDeploymentTutorial/Pytorch/driver.py\u001b[0m in \u001b[0;36mcall_model\u001b[0;34m(images, number_results)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mselected_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_proba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnumber_results\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_proba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mselected_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselected_results\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/AKSDeploymentTutorial/Pytorch/driver.py\u001b[0m in \u001b[0;36m_label_lookup\u001b[0;34m(*label_locks)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_label_lookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlabel_locks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabel_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabel_locks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_label_lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/AKSDeploymentTutorial/Pytorch/driver.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_label_lookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlabel_locks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabel_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabel_locks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_label_lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "# jsonimg = img_url_to_json(IMAGEURL)\n",
    "# json_load_img = json.loads(jsonimg)\n",
    "# body = json_load_img[\"input\"]\n",
    "resp = predict_for({'key':open('220px-Lynx_lynx_poing.jpg', 'rb'), 'key2':open('220px-Lynx_lynx_poing.jpg', 'rb')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'key': [('n02127052 lynx, catamount', 0.9966713786125183),\n",
      "         ('n02123159 tiger cat', 0.0011281940387561917),\n",
      "         ('n02128385 leopard, Panthera pardus', 0.0007295589311979711)]}\n"
     ]
    }
   ],
   "source": [
    "pprint(resp[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can move on to [building our docker image](02_BuildImage.ipynb)."
   ]
  }
 ],
 "metadata": {
  "jupytext_format_version": "1.3",
  "jupytext_formats": "py:light",
  "kernelspec": {
   "display_name": "Python [conda env:AKSDeploymentPytorch]",
   "language": "python",
   "name": "conda-env-AKSDeploymentPytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
